import openai
from openai import OpenAI
import os
from dotenv import load_dotenv

load_dotenv()

# âœ… ìµœì‹  ë²„ì „(1.0.0+) ë°©ì‹ì˜ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def get_gpt_response(prompt):
    try:
        # âœ… ìµœì‹  ë°©ì‹ì˜ API í˜¸ì¶œ
        response = client.chat.completions.create(
            model="gpt-4o-mini", # ë˜ëŠ” "gpt-3.5-turbo"
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ì „ë¬¸ ë²ˆì—­ê°€ì•¼. ì…ë ¥ëœ ë¬¸ì¥ì„ ì§€ì •ëœ ì–¸ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë²ˆì—­í•´ì¤˜."},
                {"role": "user", "content": prompt}
            ]
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"GPT API ì—ëŸ¬ ë°œìƒ: {e}")
        return prompt  # ì—ëŸ¬ ë°œìƒ ì‹œ ì›ë¬¸ ë°˜í™˜

# #ê¸°ë³¸ í…ŒìŠ¤íŠ¸
# if __name__ == "__main__":
#     stt_output = "ì¡¸ì—…í•  ìˆ˜ ìˆê² ì§€?"
#     answer = get_gpt_response(stt_output)
#     print("ğŸ™‹ ë‚˜:" , stt_output)
#     print("ğŸ¤– GPT ì‘ë‹µ:", answer)
#     print("-" * 40)

# #ì—¬ëŸ¬ ë¬¸ì¥ì„ í•œêº¼ë²ˆì— í…ŒìŠ¤íŠ¸
# questions = [
#     "ì•ˆë…•, ë°˜ê°€ì›Œ.",
#     "ì˜¤ëŠ˜ í•  ì¼ ì¶”ì²œí•´ì¤˜!",
#     "ì˜¤ëŠ˜ ì„œìš¸ì—ì„œ ë²šê½ƒ ë³´ëŸ¬ê°ˆ ë§Œí•œ ê³³ì´ ì–´ë”” ìˆì„ê¹Œ?",
#     "ì„œìš¸ì—ì„œ 10000ì›ìœ¼ë¡œ ì¥ë³´ê³  ì‹¶ì€ë° ì–´ë–¤ ê±¸ êµ¬ë§¤í• ê¹Œ?",
# ]

# for q in questions:
#     print(f"ğŸ™‹ ì‚¬ìš©ì: {q}")
#     print(f"ğŸ¤– ë‚˜ë§Œì˜ ìŒì„± ë¹„ì„œ: {get_gpt_response(q)}")
#     print("-" * 40)