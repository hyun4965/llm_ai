import os
from pydub import AudioSegment
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key)

def convert_webm_to_wav(webm_path: str, wav_path: str) -> None:
    """
    webm íŒŒì¼ì„ wav íŒŒì¼ë¡œ ë³€í™˜ (pydub ì‚¬ìš©)
    """
    try:
        audio = AudioSegment.from_file(webm_path) # í™•ì¥ì ìë™ ì¸ì‹
        # OpenAI Whisper APIëŠ” íŒŒì¼ ìš©ëŸ‰ ì œí•œì´ ìˆìœ¼ë¯€ë¡œ ëª¨ë…¸/16kHzë¡œ ì¤„ì´ë©´ ì¢‹ìŒ
        audio = audio.set_channels(1).set_frame_rate(16000)
        audio.export(wav_path, format="wav")
        print(f"ğŸµ ë³€í™˜ ì™„ë£Œ: {wav_path}")
    except Exception as e:
        print(f"âŒ ì˜¤ë””ì˜¤ ë³€í™˜ ì‹¤íŒ¨: {e}")
        # ffmpegê°€ ì—†ìœ¼ë©´ ì—¬ê¸°ì„œ ì—ëŸ¬ê°€ ë‚©ë‹ˆë‹¤.
        raise e

def transcribe_audio_file_local(file_path: str) -> str:
    """
    OpenAI API (Whisper)ë¥¼ ì‚¬ìš©í•˜ì—¬ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    """
    try:
        print(f"ğŸ“ STT ìš”ì²­ ì¤‘ (OpenAI Whisper)...")
        
        with open(file_path, "rb") as audio_file:
            transcript = client.audio.transcriptions.create(
                model="whisper-1", 
                file=audio_file,
                language="ko" # í•œêµ­ì–´ ìš°ì„  ì¸ì‹ (í•„ìš” ì‹œ ì œê±° ê°€ëŠ¥)
            )
            
        result_text = transcript.text
        print(f"âœ… STT ê²°ê³¼: {result_text}")
        return result_text

    except Exception as e:
        print(f"âŒ STT ë³€í™˜ ì‹¤íŒ¨: {e}")
        return "ìŒì„± ì¸ì‹ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."